---
title: "Lab06"
author: "Lily"
date: "`r Sys.Date()`"
output: github_document
always_allow_html: true
---
  
```{r}
knitr::opts_chunk$set(echo = TRUE)
```

```{r install-libraries}
library(tidytext)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(forcats)
```

## Read In Data

```{r read-data, cache=TRUE}
if (!file.exists("mtsamples.csv")) {
  download.file("https://raw.githubusercontent.com/USCbiostats/data-science-data/master/00_mtsamples/mtsamples.csv",  "mtsamples.csv", method="libcurl", timeout = 60)  
}
mts <- read.csv("mtsamples.csv")
str(mts)
mts <- as_tibble(mts)
mts
```

# Question 1

## We can use count() from dplyr to figure out how many different catagories do we have? Are these catagories related? overlapping? evenly distributed?
```{r}
specialties <- 
    mts %>%
    count(medical_specialty)
specialties %>%
    arrange(desc(n)) %>%
knitr::kable()
```
```{r}
specialties %>%
  top_n(10) %>%
  ggplot(aes(x = n, y = fct_reorder(medical_specialty,n))) + 
   geom_col()
```

### The data has related categories and it is semi-evenly distributed 

# Question 2

## Tokenize the the words in the transcription column
##Count the number of times each token appears
##Visualize the top 20 most frequent words
##Explain what we see from this result. Does it makes sense? What insights (if any) do we get?
```{r}
mts %>% 
  unnest_tokens(word, transcription) %>%
  count(word, sort = TRUE) %>%
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(word, n))) +
  geom_col()
```
###There are a lot of stopwords that need to be filtered

# Question 3

##Redo visualization but remove stopwords before
##Bonus points if you remove numbers as well
##What do we see know that we have removed stop words? Does it give us a better idea of what the text is about?
```{r, cache = TRUE}
mts %>% 
  unnest_tokens(word, transcription) %>%
  count(word, sort = TRUE) %>%
  anti_join(stop_words, by = c("word")) %>%
  filter( !grepl(pattern = "^[0-9]+$", x = word)) %>% 
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(word, n))) +
  geom_col()
```

### Removing the stop words helps us identfiy keywords faster 

#Question 4

## repeat question 2, but this time tokenize into bi-grams. how does the result change if you look at tri-grams?
```{r}
mts %>% 
  unnest_ngrams(trigram, transcription, n=3) %>%
  count(trigram, sort = TRUE) %>%
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(trigram, n))) +
  geom_col()
```
### Trigrams returns more medical words than bigrams

#Question 5

## Using the results you got from questions 4. Pick a word and count the words that appears after and before it.
```{r}
ptbigram <- 
  mts %>% 
  unnest_ngrams(bigram, transcription, n=2) %>%
  separate(bigram,into = c("word1", "word2"), sep = " ")%>%
  select(word1, word2) %>%
  filter(word1 == "patient" | word2 == "patient")
```

#### words appearing before patient:
```{r}
ptbigram %>% 
  filter(word2 == "patient") %>%
  count(word1, sort=TRUE ) %>% 
  anti_join(stop_words, by = c("word1" ="word")) %>% 
  top_n(10) %>% 
  knitr::kable()
```

#### words appearing after patient:
```{r}
ptbigram %>% 
  filter(word1 == "patient")%>% 
  count(word2, sort=TRUE ) %>% 
  anti_join(stop_words, by = c("word2" ="word")) %>% 
  top_n(10) %>% 
  knitr::kable()
```


#Question 6

## Which words are most used in each of the specialties. you can use group_by() and top_n() from dplyr to have the calculations be done within each specialty. Remember to remove stopwords. How about the most 5 used words?
```{r}
mts %>% 
  unnest_tokens(word, transcription) %>%
  group_by(medical_specialty) %>%
  count(word, sort = TRUE) %>%
  filter( !(word %in% stop_words$word) & !grepl(pattern = "^[0-9]+$", x = word)) %>% 
  top_n(5, n) %>%
  arrange(medical_specialty, desc(n)) %>%
knitr::kable()
```